{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where the file will be saved\n",
    "data_folder = \"datatest\"\n",
    "\n",
    "# Specify the text file where the US Census API is stored\n",
    "api_file = \"apikey_uscensus.txt\"\n",
    "\n",
    "# Different data series require different api requests \n",
    "# https://censusreporter.org/topics/table-codes/\n",
    "# check api link for specific table \n",
    "series_dictionary = {\n",
    "    \"B\": \"\",\n",
    "    \"S\": \"/subject\",\n",
    "    \"DP\": \"/profile\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkseries(variables):\n",
    "\n",
    "    series = None    \n",
    "\n",
    "    for var in variables:\n",
    "\n",
    "        # extract letters until first number\n",
    "        match = re.match(r\"([A-Za-z]+)\", var)\n",
    "        if match: \n",
    "            beginningstring = match.group(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Variable {var} does not start with letters, cant detect series.\")\n",
    "\n",
    "        if series is None: \n",
    "            series = beginningstring\n",
    "        else: \n",
    "            if beginningstring != series: \n",
    "                raise Exception(\"Import variables must be of the same series.\")\n",
    "\n",
    "    print(f\"All variables belong to {series} series, API link will be adjusted accordingly.\")\n",
    "\n",
    "    return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uscensus_importcsv(column_dictionary, year, output_file_name):\n",
    "\n",
    "    # Import API key from api_file\n",
    "    with open(api_file, \"r\") as file:\n",
    "        api_key = file.read()\n",
    "\n",
    "    # Extract all specified variables as list from the dictionary\n",
    "    specific_variables = list(column_dictionary.keys())\n",
    "\n",
    "    # Add NAME as additional variable which contains county and state name  \n",
    "    all_variables = [\"NAME\"] + specific_variables\n",
    "\n",
    "    # Format variables as string for the link\n",
    "    link_variables = \",\".join(all_variables)\n",
    "    print(link_variables)\n",
    "\n",
    "    # Use predefined function to check the series\n",
    "    series = checkseries(specific_variables)\n",
    "\n",
    "    dataseries = series_dictionary.get(series, None)\n",
    "\n",
    "    if dataseries is None: \n",
    "        raise Exception(f\"Series not recognized, please check if {series} is included in series_dictionary.\")\n",
    "\n",
    "    # Construct the URL with the specified variables\n",
    "    url = f\"https://api.census.gov/data/{year}/acs/acs5{dataseries}?get={link_variables}&for=county:*&key={api_key}\"\n",
    "    print(url)\n",
    "\n",
    "    #\n",
    "    ### Check files\n",
    "    #\n",
    "\n",
    "    # Check if data_folder exists, if not create the folder\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"{data_folder} does not exist, creating...\")\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(data_folder, output_file_name)\n",
    "\n",
    "    # Check if file already exists, if yes delete\n",
    "    if os.path.exists(output_file_path):\n",
    "        print(\"Existing file found, removing...\")\n",
    "        os.remove(output_file_path)\n",
    "\n",
    "    #\n",
    "    ### Make request to api\n",
    "    #\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Headers in the original data response\n",
    "        original_headers = data[0]\n",
    "        print(original_headers)\n",
    "        \n",
    "        # Reorder the headers \n",
    "        reordered_headers = [\"state\", \"county\"] + all_variables\n",
    "\n",
    "        # If header (column name) is in the dictionary, the variable should be renamed\n",
    "        # If header is not in the dictionary the variable should be capitalized (first letter uppercase, remaining one's lowercase)\n",
    "        descriptive_headers = []\n",
    "        for header in reordered_headers:\n",
    "            if header in column_dictionary:\n",
    "                    descriptive_headers.append(column_dictionary[header])\n",
    "            else:\n",
    "                descriptive_headers.append(header.capitalize())\n",
    "\n",
    "        print(descriptive_headers)\n",
    "\n",
    "        imported_variables = []\n",
    "        for header in descriptive_headers:\n",
    "            if header in column_dictionary.values():\n",
    "                imported_variables.append(header)\n",
    "        print(f\"Imported Variables:{imported_variables}\")\n",
    "\n",
    "        # Write data to CSV with reordered and renamed headers\n",
    "        with open(output_file_path, \"w\", newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(descriptive_headers)  # Write header row with descriptive names\n",
    "            \n",
    "            # Reorder each row based on the specified order and write to CSV\n",
    "            for row in data[1:]:\n",
    "                reordered_row = [row[original_headers.index(col)] for col in reordered_headers]\n",
    "                writer.writerow(reordered_row)\n",
    "        \n",
    "        print(f\"Data saved to {output_file_path}\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "    return output_file_path, imported_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal modify for csv\n",
    "\n",
    "def uscensus_modify(output_file_path, specific_variables):\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    # Latin Encoding (Puerto Rico County Names with special characters)\n",
    "    # State / County as string to keep leading 0 \n",
    "    df = pd.read_csv(f\"{output_file_path}\", encoding=\"latin-1\", dtype={\"State\": str, \"County\": str})\n",
    "\n",
    "    # 1. Merge the \"State\" Code and \"County\" Code to create the \"FIPS Code\" column\n",
    "    df[\"FIPS Code\"] = df[\"State\"].astype(str).str.zfill(2) + df[\"County\"].astype(str).str.zfill(3)\n",
    "\n",
    "    # 2. Split the Name into \"County Name\" and \"State Name\"\n",
    "    df[[\"County Name\", \"State Name\"]] = df[\"Name\"].str.split(', ', expand=True)\n",
    "\n",
    "    # 3. Specify columns to keep\n",
    "    # Start with additional columns to keep\n",
    "    additional_columns = [\"FIPS Code\", \"County Name\", \"State Name\"]\n",
    "    # Add the imported columns specified in the dictionary, except the first one (\"NAME\")\n",
    "    imported_columns = specific_variables\n",
    "    # Combine both lists\n",
    "    columns_to_keep = additional_columns + imported_columns\n",
    "    # Check if all specified columns are in the df\n",
    "    for col in columns_to_keep: \n",
    "        if col not in df.columns:\n",
    "            raise Exception(f\"{col} not in df, check again\")\n",
    "    # Keep all the desired columns\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # 4. Remove all counties in Puerto Rico \n",
    "    df = df[df[\"State Name\"] != \"Puerto Rico\"]\n",
    "\n",
    "    # 5. Check if df contains 3144 counties \n",
    "    if df.shape[0] != 3144: \n",
    "        raise Exception(f\"{df.shape[0]} instead of 3144 counties in df, check again\")\n",
    "\n",
    "    # 6. Overwrite the modified DataFrame back to the original file\n",
    "    df.to_csv(f\"{output_file_path}\", index=False)\n",
    "    print(f\"{output_file_path} has been modified and saved\")\n",
    "\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired variables and rename them\n",
    "education_dictionary = {\n",
    "    # \"USCensusVariable\": \"Desired Name\" \n",
    "    \"S1501_C01_006E\": \"Population 25 years and over\",\n",
    "    \"S1501_C01_014E\": \"Population 25 years and over!Cumulative!High school graduate or higher\",\n",
    "    \"S1501_C01_015E\": \"Population 25 years and over!Cumulative!Bachelors degree or higher\"\n",
    "}\n",
    "\n",
    "# Specify the desired year of the data\n",
    "education_year = \"2023\"\n",
    "\n",
    "# Specify the file name for the csv file\n",
    "education_output_file_name = \"education_county_2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME,S1501_C01_006E,S1501_C01_014E,S1501_C01_015E\n",
      "All variables belong to S series, API link will be adjusted accordingly.\n",
      "https://api.census.gov/data/2023/acs/acs5/subject?get=NAME,S1501_C01_006E,S1501_C01_014E,S1501_C01_015E&for=county:*&key=64db02f0ff22a5b790004c6424221aeb9d642921\n",
      "Existing file found, removing...\n",
      "['NAME', 'S1501_C01_006E', 'S1501_C01_014E', 'S1501_C01_015E', 'state', 'county']\n",
      "['State', 'County', 'Name', 'Population 25 years and over', 'Population 25 years and over!Cumulative!High school graduate or higher', 'Population 25 years and over!Cumulative!Bachelors degree or higher']\n",
      "Imported Variables:['Population 25 years and over', 'Population 25 years and over!Cumulative!High school graduate or higher', 'Population 25 years and over!Cumulative!Bachelors degree or higher']\n",
      "Data saved to datatest\\education_county_2023.csv\n",
      "datatest\\education_county_2023.csv has been modified and saved\n"
     ]
    }
   ],
   "source": [
    "education_output_file_path, education_specific_variables = uscensus_importcsv(education_dictionary, education_year, education_output_file_name)\n",
    "\n",
    "uscensus_modify(education_output_file_path, education_specific_variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
