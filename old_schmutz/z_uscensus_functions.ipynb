{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uscensus_checkseries(variables):\n",
    "\n",
    "    series = None    \n",
    "\n",
    "    for var in variables:\n",
    "\n",
    "        # extract letters until first number\n",
    "        match = re.match(r\"([A-Za-z]+)\", var)\n",
    "        if match: \n",
    "            beginningstring = match.group(1)\n",
    "        else:\n",
    "            raise ValueError(f\"Variable {var} does not start with letters, cant detect series.\")\n",
    "\n",
    "        if series is None: \n",
    "            series = beginningstring\n",
    "        else: \n",
    "            if beginningstring != series: \n",
    "                raise Exception(\"Import variables must be of the same series.\")\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uscensus_importcsv(column_dictionary, year, output_file_name):\n",
    "\n",
    "    # Import API key from api_file\n",
    "    with open(api_file, \"r\") as file:\n",
    "        api_key = file.read()\n",
    "\n",
    "    # Extract all specified variables as list from the dictionary\n",
    "    specific_variables = list(column_dictionary.keys())\n",
    "\n",
    "    # Add NAME as additional variable which contains county and state name  \n",
    "    all_variables = [\"NAME\"] + specific_variables\n",
    "\n",
    "    # Format variables as string for the link\n",
    "    link_variables = \",\".join(all_variables)\n",
    "    print(link_variables)\n",
    "\n",
    "    # Use predefined function to check the series\n",
    "    series = uscensus_checkseries(specific_variables)\n",
    "\n",
    "    dataseries = series_dictionary.get(series, None)\n",
    "\n",
    "    if dataseries is None: \n",
    "        raise Exception(f\"Series not recognized, please check if {series} is included in series_dictionary.\")\n",
    "\n",
    "    # Construct the URL with the specified variables\n",
    "    url = f\"https://api.census.gov/data/{year}/acs/acs5{dataseries}?get={link_variables}&for=county:*&key={api_key}\"\n",
    "    print(url)\n",
    "\n",
    "    #\n",
    "    ### Check files\n",
    "    #\n",
    "\n",
    "    # Check if data_folder exists, if not create the folder\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"{data_folder} does not exist, creating...\")\n",
    "        os.makedirs(data_folder)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(data_folder, output_file_name)\n",
    "\n",
    "    # Check if file already exists, if yes delete\n",
    "    if os.path.exists(output_file_path):\n",
    "        print(\"Existing file found, removing...\")\n",
    "        os.remove(output_file_path)\n",
    "\n",
    "    #\n",
    "    ### Make request to api\n",
    "    #\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Headers in the original data response\n",
    "        original_headers = data[0]\n",
    "        print(original_headers)\n",
    "        \n",
    "        # Reorder the headers \n",
    "        reordered_headers = [\"state\", \"county\"] + all_variables\n",
    "\n",
    "        # If header (column name) is in the dictionary, the variable should be renamed\n",
    "        # If header is not in the dictionary the variable should be capitalized (first letter uppercase, remaining one's lowercase)\n",
    "        descriptive_headers = []\n",
    "        for header in reordered_headers:\n",
    "            if header in column_dictionary:\n",
    "                    descriptive_headers.append(column_dictionary[header])\n",
    "            else:\n",
    "                descriptive_headers.append(header.capitalize())\n",
    "\n",
    "        print(descriptive_headers)\n",
    "\n",
    "        imported_variables = []\n",
    "        for header in descriptive_headers:\n",
    "            if header in column_dictionary.values():\n",
    "                imported_variables.append(header)\n",
    "        print(f\"Imported Variables:{imported_variables}\")\n",
    "\n",
    "        # Write data to CSV with reordered and renamed headers\n",
    "        with open(output_file_path, \"w\", newline='') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow(descriptive_headers)  # Write header row with descriptive names\n",
    "            \n",
    "            # Reorder each row based on the specified order and write to CSV\n",
    "            for row in data[1:]:\n",
    "                reordered_row = [row[original_headers.index(col)] for col in reordered_headers]\n",
    "                writer.writerow(reordered_row)\n",
    "        \n",
    "        print(f\"Data saved to {output_file_path}\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "\n",
    "    return output_file_path, imported_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal modify for csv\n",
    "\n",
    "def uscensus_modify(output_file_path, specific_variables):\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    # Latin Encoding (Puerto Rico County Names with special characters)\n",
    "    # State / County as string to keep leading 0 \n",
    "    df = pd.read_csv(f\"{output_file_path}\", encoding=\"latin-1\", dtype={\"State\": str, \"County\": str})\n",
    "\n",
    "    # 1. Merge the \"State\" Code and \"County\" Code to create the \"FIPS Code\" column\n",
    "    df[\"fips_code\"] = df[\"State\"].astype(str).str.zfill(2) + df[\"County\"].astype(str).str.zfill(3)\n",
    "\n",
    "    # 2. Split the Name into \"County Name\" and \"State Name\"\n",
    "    df[[\"county_name\", \"state_name\"]] = df[\"Name\"].str.split(', ', expand=True)\n",
    "\n",
    "    # 3. Specify columns to keep\n",
    "    # Start with additional columns to keep\n",
    "    additional_columns = [\"fips_code\", \"county_name\", \"state_name\"]\n",
    "    # Add the imported columns specified in the dictionary, except the first one (\"NAME\")\n",
    "    imported_columns = specific_variables\n",
    "    # Combine both lists\n",
    "    columns_to_keep = additional_columns + imported_columns\n",
    "    # Check if all specified columns are in the df\n",
    "    for col in columns_to_keep: \n",
    "        if col not in df.columns:\n",
    "            raise Exception(f\"{col} not in df, check again\")\n",
    "    # Keep all the desired columns\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    # 4. Remove all counties in Puerto Rico \n",
    "    df = df[df[\"state_name\"] != \"Puerto Rico\"]\n",
    "\n",
    "    # 5. Check if df contains 3144 counties \n",
    "    if df.shape[0] != 3144: \n",
    "        raise Exception(f\"{df.shape[0]} instead of 3144 counties in df, check again\")\n",
    "\n",
    "    # 6. Overwrite the modified DataFrame back to the original file\n",
    "    df.to_csv(f\"{output_file_path}\", index=False)\n",
    "    print(f\"{output_file_path} has been modified and saved\")\n",
    "\n",
    "    df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
